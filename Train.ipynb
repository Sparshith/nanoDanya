{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcb1e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append(str((Path.cwd() / \"nanochat\").resolve()))\n",
    "from nanochat.gpt import GPT, GPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e413305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2652, 512, 185693, 18546)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path('data/processed/')\n",
    "meta = pickle.loads((data_dir / 'meta.pkl').read_bytes())\n",
    "vocab_size = meta['vocab_size']\n",
    "context_length = meta['context_length']\n",
    "train_tokens = np.fromfile(data_dir / 'train.bin', dtype=np.uint16)\n",
    "val_tokens = np.fromfile(data_dir / 'val.bin', dtype=np.uint16)\n",
    "(vocab_size, context_length, len(train_tokens), len(val_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2e207ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanogpt_iter(data, block_size, batch_size, device):\n",
    "    max_start = data.size(0) - block_size - 1\n",
    "    idx = torch.randint(0, max_start, (batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in idx]).to(device)\n",
    "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in idx]).to(device)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ad20abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "config = GPTConfig(sequence_len=context_length, vocab_size=vocab_size, n_layer=4, n_head=4, n_kv_head=4, n_embd=256)\n",
    "model = GPT(config).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44f67e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0001/1000 train 8.0434 val 7.9046\n",
      "step 0050/1000 train 5.7657 val 5.9648\n",
      "step 0100/1000 train 5.1905 val 5.6379\n",
      "step 0150/1000 train 4.8138 val 5.3580\n",
      "step 0200/1000 train 4.5565 val 5.1652\n",
      "step 0250/1000 train 4.1780 val 4.9470\n",
      "step 0300/1000 train 4.0527 val 4.9744\n",
      "step 0350/1000 train 3.7909 val 4.8884\n",
      "step 0400/1000 train 3.6483 val 4.9511\n",
      "step 0450/1000 train 3.3473 val 4.8890\n",
      "step 0500/1000 train 3.2232 val 4.9984\n",
      "step 0550/1000 train 3.0599 val 5.0294\n",
      "step 0600/1000 train 2.8667 val 4.9826\n",
      "step 0650/1000 train 2.7100 val 5.1352\n",
      "step 0700/1000 train 2.4854 val 5.1068\n",
      "step 0750/1000 train 2.3693 val 5.3237\n",
      "step 0800/1000 train 2.2386 val 5.3581\n",
      "step 0850/1000 train 2.0834 val 5.3924\n",
      "step 0900/1000 train 1.9140 val 5.4725\n",
      "step 0950/1000 train 1.8383 val 5.4555\n",
      "step 1000/1000 train 1.7137 val 5.5194\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.from_numpy(train_tokens.astype(np.int64))\n",
    "val_data = torch.from_numpy(val_tokens.astype(np.int64))\n",
    "train_data, val_data = train_data.to(device), val_data.to(device)\n",
    "max_iters = 1000\n",
    "eval_interval = 50\n",
    "batch_size = 32\n",
    "for step in range(1, max_iters + 1):\n",
    "    xb, yb = nanogpt_iter(train_data, context_length, batch_size, device)\n",
    "    logits = model(xb)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.view(-1, logits.size(-1)), yb.view(-1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    if step % eval_interval == 0 or step == 1:\n",
    "        xb_val, yb_val = nanogpt_iter(val_data, context_length, batch_size, device)\n",
    "        with torch.no_grad():\n",
    "            logits_val = model(xb_val)\n",
    "            val_loss = torch.nn.functional.cross_entropy(logits_val.view(-1, logits_val.size(-1)), yb_val.view(-1))\n",
    "        print(f'step {step:04d}/{max_iters} train {loss.item():.4f} val {val_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4776000",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model': model.state_dict(), 'meta': {'model_config': config.__dict__, 'tokenizer': meta}}, 'chess_min.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
